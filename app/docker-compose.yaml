services:
  frontend_app:
    build:
      dockerfile: frontend.dockerfile
      context: frontend/
    ports:
      - 80:80
    depends_on: 
      - backend_app
  
  backend_app:
    build:
      dockerfile: backend.dockerfile
      context: backend/
    ports:
      - 8080:8080
    depends_on: 
      - backend_db
      - local_llm  
    volumes:
      - ./backend/configs:/app/configs 
    env_file:
    - ./database/db_conn.env
  backend_db:
    build:
      dockerfile: db.dockerfile
      context: database/
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - ./database/pgdata:/var/lib/postgresql/18/data 

  local_llm:
    build:
      dockerfile: local-llm.dockerfile
      context: local-llm/
    ports:
      - 11434:11434  #exposed for tests, still might change
    volumes:
      - ollama_data:/root/.ollama  #persist model cache
    mem_limit: 4g  #4gb ram limit, might change tho. Also currently only limiting wheh docker compose up, no swarm
    mem_reservation: 2g 
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3

#named volume for model persistence
volumes:
  ollama_data:
    driver: local